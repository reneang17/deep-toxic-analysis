{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        text = text.permute(1, 0)\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM =  20002\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [2,3,4]\n",
    "OUTPUT_DIM = 6\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX =  1\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES ,OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0819,  0.0175,  0.1646,  ..., -0.1461,  0.0274, -0.1393],\n",
       "        [-0.1278, -0.1142,  0.0214,  ..., -0.0455, -0.1260,  0.1340],\n",
       "        [-0.0189, -0.2308,  0.6949,  ..., -0.1919,  0.7575,  0.1874],\n",
       "        ...,\n",
       "        [-1.0605, -0.3805, -0.4359,  ..., -0.3696, -0.0038, -0.2723],\n",
       "        [-0.8599,  0.3470,  0.8638,  ..., -0.1740, -0.2555,  0.0840],\n",
       "        [ 0.3404,  0.0319,  0.0420,  ...,  0.4027,  0.3248, -1.5861]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model.load_state_dict(torch.load('tut2-model.pt'))\n",
    "\n",
    "#test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "model.embedding.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20002, 100])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1221cbcc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "import spacy\n",
    "import os\n",
    "import re\n",
    "spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "TEXT = pickle.load(open('./custom_embeddings/train_data_field', 'rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.vocab.Vocab at 0x121f50fd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153164"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataFields = {\"comment_text\": (\"comment_text\", TEXT)}\n",
    "\n",
    "test_data = data.TabularDataset(path='./data/test.json', \n",
    "                                            format='json',\n",
    "                                            fields=dataFields, \n",
    "                                            skip_header=False)\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_iterator = torchtext.data.Iterator(test_data, batch_size=64, device=device, \n",
    "                                     sort=False, sort_within_batch=False, \n",
    "                                     repeat=False,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20002, 100])\n"
     ]
    }
   ],
   "source": [
    "TEXT.unk_token\n",
    "\n",
    "\n",
    "print(TEXT.vocab.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0819,  0.0175,  0.1646, -0.1562, -0.1353,  0.0808,  0.1197, -0.0839,\n",
       "         0.0643,  0.0129, -0.0114,  0.0017,  0.0051, -0.0195,  0.0776,  0.0170,\n",
       "         0.0598, -0.0418,  0.1261, -0.0057,  0.1347,  0.1081, -0.0690,  0.0587,\n",
       "         0.0897,  0.0450,  0.0819,  0.0252, -0.0180,  0.0771, -0.0226,  0.1343,\n",
       "        -0.0390,  0.1087, -0.0346, -0.0487, -0.0366,  0.0294, -0.1057,  0.0217,\n",
       "        -0.0896, -0.0056, -0.0024, -0.0583,  0.0304, -0.0205, -0.0783, -0.0511,\n",
       "         0.1128, -0.0443, -0.0816, -0.0763, -0.0602,  0.0656, -0.3388, -0.0691,\n",
       "         0.0897,  0.0461,  0.1059,  0.2282, -0.0929, -0.0346, -0.1973,  0.0348,\n",
       "         0.3062,  0.0781,  0.1258,  0.0681,  0.1165, -0.1356, -0.1326,  0.1248,\n",
       "        -0.0889, -0.0454,  0.0026,  0.0952,  0.0121,  0.0905, -0.1676,  0.1223,\n",
       "         0.0909, -0.1292,  0.0008, -0.0408, -0.2441,  0.1631,  0.0282, -0.0344,\n",
       "         0.0164, -0.1831,  0.1841,  0.2541, -0.0341,  0.2432, -0.0120, -0.1292,\n",
       "        -0.0995, -0.1461,  0.0274, -0.1393])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors[TEXT.vocab.stoi['mofuckas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPreds=[]\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for batch in test_iterator:\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "        text = batch.comment_text    \n",
    "        predictions = model(text).squeeze(1)         \n",
    "        myPreds+=[torch.sigmoid(predictions).detach().numpy()]\n",
    "    \n",
    "        torch.cuda.empty_cache()\n",
    "myPreds = np.vstack(myPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF= pd.read_csv(\"./data/test.csv\")\n",
    "for i, col in enumerate([\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]):\n",
    "    testDF[col] = myPreds[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF.drop(\"comment_text\", axis=1).to_csv(\"submission_convolutional_test_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
