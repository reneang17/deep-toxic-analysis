{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        text = text.permute(1, 0)\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM =  20002\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [2,3,4]\n",
    "OUTPUT_DIM = 6\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX =  1\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES ,OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model.load_state_dict(torch.load('tut2-model.pt'))\n",
    "\n",
    "#test_loss, test_acc = evaluate(model, test_iterator, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext.vocab as vocab\n",
    "from torchtext import data\n",
    "\n",
    "custom_embeddings = vocab.Vectors(name = 'custom_embeddings/embeddings_conv.txt',\n",
    "                                  cache = 'custom_embeddings')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "emdeding_dict = custom_embeddings.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.0865e-02,  1.1826e-01,  2.5153e-01, -9.5067e-02, -9.5174e-02,\n",
       "         1.2393e-01, -1.4499e-01,  5.6593e-02,  9.0250e-02,  3.1946e-03,\n",
       "        -8.6432e-03, -8.3976e-02,  3.7212e-02, -7.1502e-02,  1.2413e-01,\n",
       "        -8.3172e-03,  2.7153e-02, -3.3595e-02, -4.7731e-03,  2.6655e-01,\n",
       "         1.8346e-01, -2.8661e-02, -9.5511e-02, -1.0686e-02,  3.5756e-01,\n",
       "        -1.6515e-02, -4.6183e-02, -8.7500e-02,  1.3388e-01,  3.9147e-04,\n",
       "        -3.1318e-02,  9.4908e-02,  2.0891e-02,  6.6893e-02, -1.6742e-02,\n",
       "         8.6748e-02,  2.0689e-02,  4.6168e-02, -4.0032e-02, -6.3711e-02,\n",
       "        -1.7659e-01, -6.8515e-02,  4.6157e-02, -1.2917e-01,  1.4088e-02,\n",
       "        -3.6902e-02,  2.8122e-02, -7.9011e-02,  4.2249e-02, -7.9993e-02,\n",
       "         3.7146e-02,  1.0368e-02,  5.1287e-02,  9.8828e-02, -4.1137e-01,\n",
       "        -1.3085e-01,  1.6571e-02, -7.9508e-02,  1.8312e-01, -1.7528e-03,\n",
       "        -4.8732e-02,  6.4475e-02, -2.7902e-01, -1.7228e-01,  2.7803e-01,\n",
       "        -1.2206e-02,  2.9109e-01,  6.2339e-02,  1.6929e-01, -6.1061e-02,\n",
       "        -2.1569e-01, -8.9092e-02, -3.4017e-01, -7.1877e-02,  7.6816e-02,\n",
       "         1.4270e-01, -4.2744e-02,  9.8367e-03, -1.4661e-01, -4.7016e-02,\n",
       "         2.7869e-01, -1.1099e-01, -5.7423e-02,  1.1100e-02, -1.5015e-01,\n",
       "        -8.7082e-02,  1.7910e-01, -1.3084e-01, -4.3226e-02, -1.4536e-01,\n",
       "        -3.9775e-02,  1.1618e-01, -5.6328e-02,  2.2235e-01, -7.2047e-02,\n",
       "        -5.2961e-02, -1.2936e-01, -1.3189e-01,  1.5528e-02, -9.0639e-03])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_embeddings.vectors[custom_embeddings.stoi['<unk>']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kir quiet or kill you bitch"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.tokenizer(\"kir quiet or kill you bitch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    #indexed = [custom_embeddings.stoi[t] for t in tokenized]\n",
    "    indexed=[]\n",
    "    for t in tokenized:\n",
    "        try: indexed.append(custom_embeddings.stoi[t])\n",
    "        except KeyError: indexed.append(custom_embeddings.stoi['<unk>'])\n",
    "            \n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    return list(prediction.squeeze().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.9999),\n",
       " tensor(0.5946),\n",
       " tensor(0.9965),\n",
       " tensor(0.7356),\n",
       " tensor(0.9938),\n",
       " tensor(0.1544)]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"retaxrded quiet or kill you fucking stupid looser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(1, 'a'), (2, 'b')])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic= {1:'a' ,2 :'b'}\n",
    "dic.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
