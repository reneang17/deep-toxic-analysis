{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "import spacy\n",
    "import os\n",
    "import re\n",
    "\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def tokenizer(text):\n",
    "    token = [t.text for t in spacy_en.tokenizer(text)]\n",
    "#    if len(token) < FILTER_SIZES[-1]:\n",
    "    for i in range(1, 7 ):\n",
    "        token.append('<PAD>')\n",
    "    return token\n",
    "\n",
    "\n",
    "TEXT = data.Field(lower=True,include_lengths=False,tokenize=tokenizer, stop_words = _stopwords)\n",
    "\n",
    "LABEL = data.Field(sequential=False, \n",
    "                         use_vocab=False, \n",
    "                         pad_token=None, \n",
    "                            unk_token=None, dtype = torch.float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataFields = {\"comment_text\": (\"comment_text\", TEXT), \n",
    "              'toxic': (\"toxic\", LABEL), \n",
    "              'severe_toxic': (\"severe_toxic\", LABEL),\n",
    "              'threat': (\"threat\", LABEL), \n",
    "              'obscene': (\"obscene\", LABEL),\n",
    "              'insult': (\"insult\", LABEL), \n",
    "              'identity_hate': (\"identity_hate\", LABEL)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/'\n",
    "data_name = 'resampled_train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= data.TabularDataset(path=data_dir+data_name, \n",
    "                                            format='json',\n",
    "                                            fields=dataFields, \n",
    "                                            skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "SEED = 3\n",
    " \n",
    "\n",
    "train_data, val_data = dataset.split(split_ratio=0.9,random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 20_000\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "\n",
    "#pickle.dump(TEXT, open('./custom_embeddings/train_data_field', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.vocab.Vocab at 0x1a77737f28>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256 #only change\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data, val_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key=lambda x: len(x.comment_text),\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_iterator:\n",
    "    aux = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   44,     0,   282, 18020,  2323,  3993,   583,     2,  2591,  2381,\n",
       "        12761,  2074,  2304,   140,   282,   152,   429,     2,   282,    63,\n",
       "         3127,   304,   556,   295,   518,     0,     0, 12088,   282,  4123,\n",
       "          137,  3483,     0,   405,   103,    73, 11007,  1509,    31,   173,\n",
       "          350,   424,     0,   280,     2,    31,    31,   161,  4877,   529,\n",
       "         7574, 13301,  1218,    41,     0,  2165,   164,   242,  1070,   152,\n",
       "          101,    44,    41,   103,    45,  3015,     3,     0,   583,    32,\n",
       "         6634, 13149,     3,  2369,     0,   366,   214,   782,  1832,  1269,\n",
       "           49,   355,    26,   103,     0, 19294,   287,   337,   109,   937,\n",
       "         1623,   266,  3971,   252,   701,  5597,  1951,    16,   472,   179,\n",
       "         4549,     0,    19,   171,  3922,   147,   282,   217,  3221,  3999,\n",
       "          600,   355,   545,    31,   157,   184,    67,  5026,     0,   282,\n",
       "            0,  1767,    19,  1505,  1102,   748,   468,   184,   846,  4759,\n",
       "            0,  1614,     2,  1250,   308,   550,  4294,   637,   182,     8,\n",
       "         1220,    45,   459,   761,     3,  2105,   272,    64,     3,     2,\n",
       "          289,    53,    74,  8536,  2644,     2,   114,  4193,     0,     0,\n",
       "           77,   124,  1843,   466,   108,  1128,     3,   728,  2590,  4282,\n",
       "         4426,   224,   224,  9286,  5486,   164,    11,  2594,     0,   981,\n",
       "            0,   782,   506,   748,   224,     2,    35,  5202,   420,  1764,\n",
       "          497,   338,   282,  1056,    35,    43,   142,  3287,    51,   282,\n",
       "          600,    16,     0,     5,  5704,    43,    17,  3858,    12,  2243,\n",
       "           39,    53,    25,  6304,   140,   543,  2702,  2580,   282,    77,\n",
       "          112,  1078,  2206,  3011,     7,   108,  6673,     9,   152,    53,\n",
       "          140,     0,   167,  8090,     0,     9,  4731,  9351,   131, 10800,\n",
       "           44,  4843,  1784,   869,   142,   899,   478,   282,  3330,   267,\n",
       "         2192,    35,   472,     5,     2,  6985])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux.comment_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "yFields = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "iaux=0\n",
    "for batch in valid_iterator:\n",
    "    iaux+=1\n",
    "    aux = batch\n",
    "    aux2= torch.stack([getattr(batch, y) for y in yFields])\n",
    "    if iaux==20: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "        \n",
    "torch.transpose( torch.stack([getattr(aux, y) for y in yFields]),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux.comment_text[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux.toxic.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        text = text.permute(1, 0)\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab) # 20002\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [2,3,4,5,6]\n",
    "OUTPUT_DIM = 6\n",
    "DROPOUT = 0.8\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] # 1\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES ,OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,203,706 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([191, 256])\n",
      "=============================================================================\n",
      "                      Kernel Shape        Output Shape   Params Mult-Adds\n",
      "Layer                                                                    \n",
      "0_embedding           [100, 20002]     [256, 191, 100]  2.0002M   2.0002M\n",
      "1_convs.Conv2d_0  [1, 100, 2, 100]  [256, 100, 190, 1]    20.1k      3.8M\n",
      "2_convs.Conv2d_1  [1, 100, 3, 100]  [256, 100, 189, 1]    30.1k     5.67M\n",
      "3_convs.Conv2d_2  [1, 100, 4, 100]  [256, 100, 188, 1]    40.1k     7.52M\n",
      "4_convs.Conv2d_3  [1, 100, 5, 100]  [256, 100, 187, 1]    50.1k     9.35M\n",
      "5_convs.Conv2d_4  [1, 100, 6, 100]  [256, 100, 186, 1]    60.1k    11.16M\n",
      "6_dropout                        -          [256, 500]        -         -\n",
      "7_fc                      [500, 6]            [256, 6]   3.006k      3.0k\n",
      "-----------------------------------------------------------------------------\n",
      "                         Totals\n",
      "Total params          2.203706M\n",
      "Trainable params      2.203706M\n",
      "Non-trainable params        0.0\n",
      "Mult-Adds              39.5032M\n",
      "=============================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_embedding</th>\n",
       "      <td>[100, 20002]</td>\n",
       "      <td>[256, 191, 100]</td>\n",
       "      <td>2000200.0</td>\n",
       "      <td>2000200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_convs.Conv2d_0</th>\n",
       "      <td>[1, 100, 2, 100]</td>\n",
       "      <td>[256, 100, 190, 1]</td>\n",
       "      <td>20100.0</td>\n",
       "      <td>3800000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_convs.Conv2d_1</th>\n",
       "      <td>[1, 100, 3, 100]</td>\n",
       "      <td>[256, 100, 189, 1]</td>\n",
       "      <td>30100.0</td>\n",
       "      <td>5670000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_convs.Conv2d_2</th>\n",
       "      <td>[1, 100, 4, 100]</td>\n",
       "      <td>[256, 100, 188, 1]</td>\n",
       "      <td>40100.0</td>\n",
       "      <td>7520000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_convs.Conv2d_3</th>\n",
       "      <td>[1, 100, 5, 100]</td>\n",
       "      <td>[256, 100, 187, 1]</td>\n",
       "      <td>50100.0</td>\n",
       "      <td>9350000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_convs.Conv2d_4</th>\n",
       "      <td>[1, 100, 6, 100]</td>\n",
       "      <td>[256, 100, 186, 1]</td>\n",
       "      <td>60100.0</td>\n",
       "      <td>11160000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[256, 500]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_fc</th>\n",
       "      <td>[500, 6]</td>\n",
       "      <td>[256, 6]</td>\n",
       "      <td>3006.0</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Kernel Shape        Output Shape     Params   Mult-Adds\n",
       "Layer                                                                        \n",
       "0_embedding           [100, 20002]     [256, 191, 100]  2000200.0   2000200.0\n",
       "1_convs.Conv2d_0  [1, 100, 2, 100]  [256, 100, 190, 1]    20100.0   3800000.0\n",
       "2_convs.Conv2d_1  [1, 100, 3, 100]  [256, 100, 189, 1]    30100.0   5670000.0\n",
       "3_convs.Conv2d_2  [1, 100, 4, 100]  [256, 100, 188, 1]    40100.0   7520000.0\n",
       "4_convs.Conv2d_3  [1, 100, 5, 100]  [256, 100, 187, 1]    50100.0   9350000.0\n",
       "5_convs.Conv2d_4  [1, 100, 6, 100]  [256, 100, 186, 1]    60100.0  11160000.0\n",
       "6_dropout                        -          [256, 500]        NaN         NaN\n",
       "7_fc                      [500, 6]            [256, 6]     3006.0      3000.0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in train_iterator:\n",
    "    aux=i\n",
    "    break\n",
    "\n",
    "from torchsummaryX import summary\n",
    "print(aux.comment_text.size())\n",
    "summary(model, aux.comment_text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20002, 100])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
       "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
       "        [-1.0889,  0.1550,  0.3195,  ..., -0.5389, -0.0420, -0.2176],\n",
       "        ...,\n",
       "        [ 1.3330,  0.2984,  1.5541,  ...,  0.3570,  0.1128,  0.7918],\n",
       "        [-0.0296,  0.9497,  0.1028,  ...,  0.0112,  0.0560, -0.2208],\n",
       "        [ 0.0578,  0.0760, -0.1415,  ...,  0.8504,  0.2324,  0.3153]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-1.0889,  0.1550,  0.3195,  ..., -0.5389, -0.0420, -0.2176],\n",
      "        ...,\n",
      "        [ 1.3330,  0.2984,  1.5541,  ...,  0.3570,  0.1128,  0.7918],\n",
      "        [-0.0296,  0.9497,  0.1028,  ...,  0.0112,  0.0560, -0.2208],\n",
      "        [ 0.0578,  0.0760, -0.1415,  ...,  0.8504,  0.2324,  0.3153]])\n"
     ]
    }
   ],
   "source": [
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-1.0889,  0.1550,  0.3195,  ..., -0.5389, -0.0420, -0.2176],\n",
      "        ...,\n",
      "        [ 1.3330,  0.2984,  1.5541,  ...,  0.3570,  0.1128,  0.7918],\n",
      "        [-0.0296,  0.9497,  0.1028,  ...,  0.0112,  0.0560, -0.2208],\n",
      "        [ 0.0578,  0.0760, -0.1415,  ...,  0.8504,  0.2324,  0.3153]])\n"
     ]
    }
   ],
   "source": [
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def roc_auc(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    #round predictions to the closest integer\n",
    "    #rounded_preds = torch.sigmoid(preds)\n",
    "    \n",
    "    #assert preds.size()==y.size()\n",
    "    \n",
    "    #reds=rounded_preds.detach().numpy()\n",
    "\n",
    "    #y=y.numpy()\n",
    "    \n",
    "    global var_y\n",
    "    global var_preds\n",
    "    var_y = y\n",
    "    var_preds = preds\n",
    "\n",
    "    acc = roc_auc_score(y, preds)\n",
    "\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    preds_list=[]\n",
    "    labels_list= []\n",
    "    epoch_loss_hist = []\n",
    "\n",
    "    \n",
    "    j = len(iterator)//10\n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text = batch.comment_text\n",
    "        \n",
    "        predictions = model(text)\n",
    "        \n",
    "        batch_labels=torch.stack([getattr(batch, y) for y in yFields]) #transpose?\n",
    "        batch_labels = torch.transpose(batch_labels,0,1)\n",
    "        \n",
    "        loss = criterion(predictions, batch_labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        preds_list+=[torch.sigmoid(predictions).detach().numpy()]\n",
    "        labels_list+=[batch_labels.numpy()]\n",
    "        \n",
    "\n",
    "                    \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        if i%j ==0:\n",
    "            epoch_loss_hist.append([loss.item(),\n",
    "            evaluate(model, valid_iterator, criterion)[0]])\n",
    "            model.train()\n",
    "        \n",
    "    return (epoch_loss / len(iterator) , epoch_loss_hist, \n",
    "           roc_auc_score(np.vstack(labels_list), np.vstack(preds_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    preds_list=[]\n",
    "    labels_list= []\n",
    "    epoch_acc=[]\n",
    "\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        i=0\n",
    "        for batch in iterator:\n",
    "            i+=1\n",
    "            text = batch.comment_text\n",
    "            \n",
    "            predictions = model(text)#.squeeze(1)\n",
    "            \n",
    "            batch_labels = torch.stack([getattr(batch, y) for y in yFields]) #transpose?\n",
    "            batch_labels = torch.transpose(batch_labels,0,1)\n",
    "            \n",
    "            loss = criterion(predictions, batch_labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            \n",
    "            preds_list+=[torch.sigmoid(predictions).detach().numpy()]\n",
    "            labels_list+=[batch_labels.numpy()]\n",
    "            \n",
    "        \n",
    "    return (epoch_loss / len(iterator),\n",
    "           roc_auc_score(np.vstack(labels_list), np.vstack(preds_list)) ,\n",
    "           np.vstack(preds_list), np.vstack(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 6m 32s\n",
      "\tTrain Loss: 0.095 | Train Acc: 85.56%\n",
      "\t Val. Loss: 0.066 |  Val. Acc: 93.73%\n",
      "Epoch: 02 | Epoch Time: 6m 36s\n",
      "\tTrain Loss: 0.071 | Train Acc: 93.28%\n",
      "\t Val. Loss: 0.061 |  Val. Acc: 95.16%\n",
      "Epoch: 03 | Epoch Time: 6m 22s\n",
      "\tTrain Loss: 0.067 | Train Acc: 94.51%\n",
      "\t Val. Loss: 0.058 |  Val. Acc: 95.96%\n",
      "Epoch: 04 | Epoch Time: 6m 27s\n",
      "\tTrain Loss: 0.064 | Train Acc: 95.12%\n",
      "\t Val. Loss: 0.057 |  Val. Acc: 96.14%\n"
     ]
    }
   ],
   "source": [
    "model.embedding.weight.requires_grad = False\n",
    "\n",
    "N_EPOCHS = 4\n",
    "best_valid_loss = float('inf')\n",
    "loss_hist= []\n",
    "UNFREEZE = 4\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, _loss_hist, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc , _preds  , _labels  = evaluate(model, valid_iterator, criterion)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    loss_hist+= _loss_hist\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'ws-model.pt')\n",
    "        \n",
    "\n",
    "    if (epoch) > UNFREEZE:\n",
    "        #unfreeze embeddings\n",
    "        model.embedding.weight.requires_grad = True \n",
    "    \n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmYFNXZ9/HvzczATI8sMyyiLAMazaMooI6o0bjEuMaA+qiBoHGLaKJGE/UJxuc1xmhek4gxLlcSjGsGt2iivAmJcd83UEgERREFRhERZR2WWe73j6oZema6unuWmoX+fa6rr+6qOlV1qrq77jrnVJ0yd0dERASgR2dnQEREug4FBRERaaCgICIiDRQURESkgYKCiIg0UFAQEZEGCgoiaZjZP8zs9M7Oh0hHUVCQLsnMPjSzr3d2Ptz9GHe/O45lm1kfM7vRzJaa2XozWxQOD4hjfSLZUFCQnGVm+Z247p7Ak8Ao4GigD/AVYBUwrhXL67RtkW2LgoJ0O2Z2nJnNNbPVZvaSmY1OmjbVzN43s3VmtsDMTkiadoaZvWhmvzGzz4GrwnEvmNn1ZvaFmX1gZsckzfOMmX03af50aUea2XPhup8ws1vNrCJiM74DDAdOcPcF7l7n7p+6+8/dfVa4PDezLyUt/y4zuyb8fKiZVZrZj83sE+BOM3vbzI5LSp9vZp+Z2d7h8P7h/lptZvPM7NC2fA+ybVJQkG4lPMDdAZwL9Af+AMw0s15hkveBrwJ9gZ8BFWa2Q9Ii9gMWA4OAa5PGLQQGAL8Cbjczi8hCurT3Aq+F+boKOC3Npnwd+Ke7r8+81ZEGA6VAGTAFuA+YlDT9KOAzd3/DzIYAfweuCee5FHjYzAa2Yf2yDVJQkO7mHOAP7v6qu9eG9f2bgf0B3P3P7v5xeOb9APAejatjPnb3m929xt03huOWuPtt7l4L3A3sAGwfsf6Uac1sOLAvcKW7b3H3F4CZabajP7C8VXtgqzrgp+6+OdyWe4HxZpYIp387HAdwKjDL3WeF++ZxYDZwbBvzINsYBQXpbsqAS8IqkNVmthoYBuwIYGbfSapaWg3sQXBWX29ZimV+Uv/B3avCj9tFrD8q7Y7A50njotZVbxVBQGmLle6+KSk/i4C3gW+GgWE8W4NCGXByk/12UDvkQbYxapyS7mYZcK27X9t0gpmVAbcBhwMvu3utmc0FkquC4uoWeDlQamaJpMAwLE36J4BrzKzY3TdEpKkCEknDg4HKpOFU21JfhdQDWBAGCgj225/c/ZwM2yE5TiUF6coKzKww6ZVPcNA/z8z2s0CxmX3DzHoDxQQHypUAZnYmQUkhdu6+hKA65ioz62lmBwDfTDPLnwgO1A+b2X+ZWQ8z629mPzGz+iqducC3zSzPzI4GDskiK/cDRwLfY2spAaCCoARxVLi8wrCxemgLN1W2cQoK0pXNAjYmva5y99kE7Qq3AF8Ai4AzANx9ATANeBlYAewJvNiB+Z0MHEBQNXQN8ABBe0cz7r6ZoLH5HeBxYC1BI/UA4NUw2UUEgWV1uOxHMmXA3ZcTbP9XwvXXj18GTAB+QhA0lwGXoWOANGF6yI5IPMzsAeAdd/9pZ+dFJFs6SxBpJ2a2r5ntHFYFHU1wZp7x7F6kK1FDs0j7GQz8heBy00rge+7+ZudmSaRlVH0kIiINVH0kIiINul310YABA3zEiBGdnQ0RkW5lzpw5n7l7xm5Nul1QGDFiBLNnz+7sbIiIdCtmtiSbdKo+EhGRBgoKIiLSQEFBREQadLs2BRHpeNXV1VRWVrJp06bMiaVTFRYWMnToUAoKClo1v4KCiGRUWVlJ7969GTFiBNHPH5LO5u6sWrWKyspKRo4c2apl5ET10YwZMGIE9OgRvM+Y0dk5EuleNm3aRP/+/RUQujgzo3///m0q0W3zJYUZM2DKFKgKe7hfsiQYBpg8ufPyJdLdKCB0D239nrb5ksIVV2wNCPWqqoLxIiLS2DYfFJYubdl4EelaVq1axdixYxk7diyDBw9myJAhDcNbtmzJahlnnnkmCxcuTJvm1ltvZUY71S0PHTqU1atXZ53+qaee4pVXXkmbZtGiRYwdO7atWctom68+Gj48qDJKNV5EYjJjRlAcX7o0+LNde22r62v79+/P3LlzAbjqqqvYbrvtuPTSSxulcXfcnR49Up/n3nnnnRnXc/7557cqf+3hqaeeYsCAAey///6dlod623xJ4dprIZFoPC6RCMaLSAzqG/KWLAH3rQ157XyFx6JFi9hjjz0477zz2HvvvVm+fDlTpkyhvLycUaNGcfXVVzekPeigg5g7dy41NTX069ePqVOnMmbMGA444AA+/fRTAP73f/+XG2+8sSH91KlTGTduHF/+8pd56aWXANiwYQP//d//zZgxY5g0aRLl5eUNAaup6667jnHjxrHffvuxePFiAB599FH2228/9tprL4488kg+/fRT3n//ff74xz/y61//mrFjx/LSSy/xySefMGHCBEaPHs2YMWN49dXgYXw1NTWcffbZjBo1imOOOSaWS4S3+aAweTJMnw4DBgTDO+wQDKuRWaSVLr4YDj00+nX22akb8s4+O3qeiy9uVVYWLFjA2WefzZtvvsmQIUO47rrrmD17NvPmzePxxx9nwYIFzeZZs2YNhxxyCPPmzeOAAw7gjjvuSLlsd+e1117j17/+dUOAufnmmxk8eDDz5s1j6tSpvPlm9OMySkpKeO211zj33HP50Y9+BMDBBx/MK6+8wptvvsmJJ57ItGnT2Hnnnfnud7/LZZddxty5c/nKV77C+eefzxFHHMG///1v5syZw2677QbAwoULufjii5k/fz5FRUU88kj7P8Npmw8KEASAu+8OPj/yiAKCSKw2p3wsdfT4Nth5553Zd999G4bvu+8+9t57b/bee2/efvvtlEGhqKiIY445BoB99tmHDz/8MOWyTzzxxGZpXnjhBSZOnAjAmDFjGDVqVGTeJk2aBMDkyZMbShpLly7lyCOPZM899+SGG25g/vz5Ked95plnOPfccwHIz8+nT58+AHzpS19izz33zJj3ttjm2xTqFRcH701PYESkhcIqlkgjRqRuyCsrg2eeadesFNf/sYH33nuP3/72t7z22mv069ePU089NWX1Ss+ePRs+5+XlUVNTk3LZvXr1apamJQ8lS3Vp6Pnnn89PfvITjj32WJ544gmuu+66Fs1fn6dMeW+LnCgpwNZ2hQ0bOjcfItu8TmrIW7t2Lb1796ZPnz4sX76cxx57rN3XcdBBB/Hggw8C8J///CdlSaTeAw88AASllwMPPBAIqq6GDBmCu3N3ffUF0Lt3b9atW9cwfNhhh/H73/8egNraWtauXdvu2xIl1qBgZkeb2UIzW2RmU1NM/42ZzQ1f75pZ9tdwtVD9b1QlBZGY1TfklZWBWfDeAQ15e++9N7vvvjt77LEH55xzTsOBuD1deOGFfPTRR4wePZpp06axxx570Ldv35Rpq6qqGDduHL/73e+YNm0aEFw9dcIJJ3DIIYew/fbbN6SdMGECDz74IHvttRcvvfQSt9xyC4899hh77rkn5eXlvPPOO+2+LVFie0azmeUB7wJHEDzE/HVgkrunDK1mdiGwl7uflW655eXl3pqH7HzwAey0E9x1F5x+eotnF8lpb7/9dkNjZy6rqamhpqaGwsJC3nvvPY488kjee+898vO7Vk18qu/LzOa4e3mmeePcknHAIndfHGbofmACEFXemgT8NK7MqE1BRNpq/fr1HH744dTU1ODu/OEPf+hyAaGt4tyaIcCypOFKYL9UCc2sDBgJPBUxfQowBWB4K+86U5uCiLRVv379mDNnTmdnI1Zxtimk6pUpqq5qIvCQu9emmuju09293N3LBw7M+NzplIqKgneVFEREosUZFCqBYUnDQ4GPI9JOBO6LMS/k5UGvXgoKIiLpxBkUXgd2MbORZtaT4MA/s2kiM/syUAK8HGNegKBdQUFBRCRabEHB3WuAC4DHgLeBB919vpldbWbjk5JOAu73uC6DSpJIqE1BRCSdWO9TcPdZ7r6ru+/s7teG465095lJaa5y92b3MMQhkVBJQaS7+uSTT5g4cSI777wzu+++O8ceeyzvvvsuI0eObNYt9sUXX8yvfvWrNq3vxhtvpCoHDxg5c0czKCiIdJT2fgSuu3PCCSdw6KGH8v7777NgwQJ+8YtfsGLFCiZOnMj999/fkLauro6HHnqIb33rW21ap4JCDlCbgkj84ug5++mnn6agoIDzzjuvYdzYsWP56le/yqRJkxoFheeee44RI0ZQVlbWaBnLly/n4IMPZuzYseyxxx48//zzAPzrX//igAMOYO+99+bkk09m/fr13HTTTXz88cccdthhHHbYYa3PeDe0bd11kUEiAevXd3YuRLq3iy+GiEcIAPDKK807RK3vOfu221LPM3Zs+n723nrrLfbZZ5+U00aPHk2PHj2YN28eY8aM4f7772/ooTTZvffey1FHHcUVV1xBbW0tVVVVfPbZZ1xzzTU88cQTFBcX88tf/pIbbriBK6+8khtuuIGnn36aAfX97ueInAsK4fM0RCQmHdhzdoP60sKoUaN49NFHGz1gp96+++7LWWedRXV1Nccffzxjx47l2WefZcGCBQ39JG3ZsoUDDjggvox2AzkXFFR9JNI2ndFz9qhRo3jooYcip0+aNIkjjzySQw45hNGjRzNo0KBmaQ4++GCee+45/v73v3Paaadx2WWXUVJSwhFHHMF998V6m1S3ojYFEWlXcfSc/bWvfY3NmzdzW1L90+uvv86zzz4LBA/b6d+/P1OnTk1ZdQSwZMkSBg0axDnnnMPZZ5/NG2+8wf7778+LL77IokWLgKBn03fffRdo3p11rsipoKD7FETiF0fP2WbGX//6Vx5//HF23nlnRo0axVVXXcWOO+7YkGbSpEm88847nHDCCSmX8cwzzzB27Fj22msvHn74YS666CIGDhzIXXfdxaRJkxg9ejT7779/QzfVU6ZM4Zhjjsm5hubYus6OS2u7zga4/HK44YZ46zZFtkXqOrt7aUvX2TlXUtiyBWJ4gp2IyDYh54ICwMaNnZsPEZGuKqeCQv2DdtSuINJy3a2qOVe19XvKqaCg5zSLtE5hYSGrVq1SYOji3J1Vq1ZRWFjY6mXk3H0KoKAg0lJDhw6lsrKSlStXdnZWJIPCwkKGDh3a6vkVFEQko4KCAkaOHNnZ2ZAOkFPVR2pTEBFJL6eCgkoKIiLpKSiIiEgDBQUREWmQU0FBbQoiIunFGhTM7GgzW2hmi8ws5XOYzewUM1tgZvPN7N4486OSgohIerFdkmpmecCtwBFAJfC6mc109wVJaXYBLgcOdPcvzKx5J+jtqKgoeFdQEBFJLc6SwjhgkbsvdvctwP3AhCZpzgFudfcvANw91uei5eVBr14KCiIiUeIMCkOAZUnDleG4ZLsCu5rZi2b2ipkdnWpBZjbFzGab2ey23lFZXKw2BRGRKHEGBUsxrmnHKfnALsChwCTgj2bWr9lM7tPdvdzdywcOHNimTOmRnCIi0eIMCpXAsKThocDHKdI86u7V7v4BsJAgSMRGQUFEJFqcQeF1YBczG2lmPYGJwMwmaR4BDgMwswEE1UmLY8yTgoKISBqxBQV3rwEuAB4D3gYedPf5Zna1mY0Pkz0GrDKzBcDTwGXuviquPIHaFERE0om1l1R3nwXMajLuyqTPDvwofHWIRALWr++otYmIdC85dUczqPpIRCQdBQUREWmQc0FBbQoiItFyLiiopCAiEk1BQUREGuRkUNiyBWpqOjsnIiJdT84FhfpnKqi0ICLSXM4FBT1TQUQkmoKCiIg0UFAQEZEGWQUFMys2sx7h513NbLyZFcSbtXjoOc0iItGyLSk8BxSa2RDgSeBM4K64MhUnlRRERKJlGxTM3auAE4Gb3f0EYPf4shUfBQURkWhZBwUzOwCYDPw9HBdrD6txUVAQEYmWbVC4GLgc+Gv4TISdCJ5/0O2oTUFEJFpWZ/vu/izwLEDY4PyZu/8gzozFRSUFEZFo2V59dK+Z9TGzYmABsNDMLos3a/FQUBARiZZt9dHu7r4WOJ7gSWrDgdNiy1WMioqCdwUFEZHmsg0KBeF9CccDj7p7NeDxZSs+eXnQq5faFEREUsk2KPwB+BAoBp4zszJgbaaZzOxoM1toZovMbGqK6WeY2Uozmxu+vtuSzLdWcbFKCiIiqWTb0HwTcFPSqCVmdli6ecwsD7gVOAKoBF43s5nuvqBJ0gfc/YIW5LnN9EwFEZHUsm1o7mtmN5jZ7PA1jaDUkM44YJG7L3b3LcD9wIQ25rd1ZsyAESOgRw8YMYJEzVoFBRGRFLKtProDWAecEr7WAndmmGcIsCxpuDIc19R/m9m/zewhMxuWakFmNqU+IK1cuTLLLIdmzIApU2DJEnCHJUtIrPiADQsrW7YcEZEckG1Q2Nndfxqe9S92958BO2WYx1KMa9o4/f+AEe4+GngCuDvVgtx9uruXu3v5wIEDs8xy6IormtUVFfs6qt7+sGXLERHJAdkGhY1mdlD9gJkdCGzMME8lkHzmPxT4ODmBu69y983h4G3APlnmJ3tLlzYblaCKqk0512u4iEhG2fZfdB5wj5n1DYe/AE7PMM/rwC5mNhL4CJgIfDs5gZnt4O7Lw8HxwNtZ5id7w4cHVUdJElTxacHQdl+ViEh3l9XpsrvPc/cxwGhgtLvvBeySYZ4a4ALgMYKD/YNhv0lXm9n4MNkPzGy+mc0DfgCc0crtiHbttVtvYw4l8rawoVRBQUSkKXNv3T1oZrbU3Ye3c34yKi8v99mzZ7dsphkz4JJLYMUKGDSIc3Z/kVnvfomPPoonjyIiXY2ZzXH38kzp2lKxnqohuWuaPBkefzz4fPPNJEZ/SZekioik0Jag0L26uSgtDd6/+EI3r4mIREjb0Gxm/yH1wd+A7WPJUVxKSoL3zz8nkYAtW6CmBvK75aOCRETikemQeFyH5KIjFBUFPeF98QXFg4NRVVXQp0/nZktEpCtJW33k7kvcfQnwGbAs/NwLGEOTew66PLOgtBCWFEBVSCIiTWXbpvAcUGhmQ4AngTOBu+LKVGxKSxvaFEBBQUSkqWyDgrl7FXAicLO7nwDsHl+2YtKkpKBnKoiINJZ1UDCzA4DJwN/Dcd2viTYsKRSH/buqpCAi0li2QeEi4HLgr+FdyTsBT8eXrZioTUFEJK1sz/a3d/f6rilw98Vm9nxMeYqP2hRERNLKtqRweZbjuraSEli/nkRBNaA2BRGRpjLdvHYMcCwwxMySH8fZB6iJM2OxCO9qLq5ZAwxQSUFEpIlM1UcfA7MJurWekzR+HfDDuDIVmzAoJDZ/gYKCiEhzaYOCu88D5pnZjLAr7O4t7OoiselzQG0KIiJNZao+etDdTwHeNLNmfSCFj9HsPsKSQtGGzwC1KYiINJWp+uii8H3b6AMpLCnkrf2CwkKVFEREmspUfbQ8fF+SLl23Ud99dnivgoKCiEhjWd2nYGbraN6F9hqCRuhL3H1xe2csFv36Be96poKISErZ3rx2A8GVSPcSPEthIjAYWAjcARwaR+baXX5+0Fd2WFJQm4KISGPZ3rx2tLv/wd3Xuftad58OHOvuDwAlUTOZ2dFmttDMFpnZ1DTpTjIzN7OMzw9ts5KShv6PVFIQEWks26BQZ2anmFmP8HVK0rSUj+U0szzgVuAYgh5VJ5lZs55Vzaw38APg1ZZlvZVKS9WmICISIdugMBk4Dfg0fJ0GnGpmRcAFEfOMAxa5+2J33wLcD0xIke7nwK+ATS3JeKuFJQUFBRGR5rIKCuGB/ZvuPiB8fdPdF7n7Rnd/IWK2IcCypOHKcFwDM9sLGObuf0u3fjObYmazzWz2ypUrs8lytKSSgtoUREQayyoomNlQM/urmX1qZivM7GEzG5ppthTjGqqazKwH8Bvgkkzrd/fp7l7u7uUDBw7MJsvR1KYgIhIp2+qjO4GZwI4EZ/v/LxyXTiUwLGl4KI2f69wb2AN4xsw+BPYHZsbe2FxfUihyBQURkSayDQoD3f1Od68JX3cBmU7ZXwd2MbORZtaT4DLWmfUT3X1NWBU1wt1HAK8A4919dss3owVKSqC6mkTPGgUFEZEmsg0Kn5nZqWaWF75OBValmyHsQO8C4DHgbeDB8KltV5vZ+HTzxqq+p1TbqDYFEZEmsr157SzgFoI2AAdeAs7MNJO7zwJmNRl3ZUTaQ7PMS9uE/R8VWxXV1X2oroaCgg5Zs4hIl5ft1UdL3X28uw9090HufjxwYsx5i0d9SaFuPQAbN3ZmZkREupZsq49S+VG75aIj1T9ToW4doCuQRESStSUopLrktOurLylUrwV0r4KISLK2BIWU3Vt0efUlheo1gEoKIiLJMj15LVWX2RCUEopiyVHceveGvDyKN+uRnCIiTWV6yE7vjspIhzGDkhI9p1lEJIVsL0mt7/V0++R53H1pHJmKXWkpiSo9p1lEpKlsn7x2IfBTYAVQF452YHRM+YpXSQmJDUHHeiopiIhslW1J4SLgy+6e9i7mbqO0lOJlnwAKCiIiybK9+mgZwTOZtw2lpSTWrQAUFEREkmW6+qj+BrXFBL2Z/h3YXD/d3W+IMW/xKSkhsTrosFVtCiIiW2WqPqq/+mhp+OoZvqC73qcAUFpK0RpVH4mINJXpktSfAZjZye7+5+RpZnZynBmLVUkJedRSWOhUVXXPG7NFROKQbZvC5VmO6x7qu7oorFNJQUQkSaY2hWOAY4EhZnZT0qQ+QE2cGYtVfVcXPWvZsCGvkzMjItJ1ZGpT+BiYDYwH5iSNXwf8MK5Mxa6+pNCzmqqqnhkSi4jkjkxtCvOAeWY2I3yS2rah/kE7+Zupqiru5MyIiHQdmaqPHnT3U4A3zazZ1Ubu3j3vaK4vKeRtVpuCiEiSTNVHF4Xvx8WdkQ5V36bARtbpPgURkQaZrj76lpntC3zk7kuavjIt3MyONrOFZrbIzKammH6emf3HzOaa2QtmtntrN6RFevWCRIIEVSopiIgkyRQUhgK/BT41s2fM7Bdm9g0zK8204LBX1VuBY4DdgUkpDvr3uvue7j4W+BXQcXdIl5RQ7OsUFEREkqQNCu5+qbt/BRgM/AT4HDgLeMvMFmRY9jhgkbsvdvctwP3AhCbLX5s0WExH3iVdWkqidr2CgohIkmx7SS0iuDehb/j6GPhPhnmGEHSkV68S2K9pIjM7H/gRQfcZX0u1IDObAkwBGD58eJZZzqCkhMSqNer7SEQkSdqSgplNN7MXgQeAA4CXgJPdvdzdz8yw7FT9R6S6gulWd98Z+DHwv6kW5O7Tw3WWDxw4MMNqs1RaSqJ6tUoKIiJJMrUpDAd6AZ8AHxGc7a/OctmVwLCk4aEEJYwo9wPHZ7nstispoXjT51RXQ3V1h61VRKRLy9SmcDSwL3B9OOoS4HUz+5eZ/SzDsl8HdjGzkWbWE5gIzExOYGa7JA1+A3ivJZlvk9JSEhuDZwZt3NhhaxUR6dIytim4uxM0LK8meNDOGoL7FsYRPKIzar4aM7sAeAzIA+5w9/lmdjUw291nAheY2deBauAL4PS2blDWSkpI1ARNHhs2QJ8+HbZmEZEuK9MdzRcRtCUcSHDgfhF4GbiDzA3NuPssYFaTcVcmfb6o2UwdpbSUBAsBPVNBRKReppJCGfAQ8EN3X94B+ek4JSUUE1x6pKAgIhLI1ND8N3d/yN2Xm9nI5AlmdmKM+YpfaSkJgmigoCAiEsgUFK5P+vxwk2kpLx/tNkpKGoKC7lUQEQlkCgoW8TnVcPeikoKISDOZgoJHfE413L2oTUFEpJlMDc07mdlMglJB/WfC4ZHRs3UDffuSILhBQUFBRCSQKSgkd2B3fZNpTYe7l7w8En0LYI3aFERE6mUKCguAge7eqEdUMxsFfBpbrjpIoqQXrFFJQUSkXqY2hZuBVD3Q1T9noVtL9C8CFBREROplCgp7uvuzTUe6+2NA93w+c5Iepf0otE0KCiIioUxBoaCV07qH0lIStlFtCiIioUxB4T0zO7bpSDM7BlgcT5Y6UHgDm0oKIiKBTA3NPwT+ZmanAHPCceUEneQdF2fGOkRpKcV166iqcrr7vXgiIu0h0/MU3gX2BJ4FRoSvZ4HR4bTurb6ksLams3MiItIlZPM8hc3AnfXDZjYA2BxnpjpM2NXFhjU1bAtNJCIibZXpGc37m9kzZvYXM9vLzN4C3gJWmNnRHZPFGNWXFNbVdXZORES6hEwlhVuAnwB9gaeAY9z9FTP7L+A+4J8x5y9epaUk+IIVGxQUREQg89VH+e7+L3f/M/CJu78C4O7vxJ+1DhB2iqerj0REApmCQvIpdNPH22fsJdXMjjazhWa2yMymppj+IzNbYGb/NrMnzawsizy3n/o2hY2ZdoOISG7IVH00xszWElyvWRR+JhwuTDejmeUBtwJHAJXA62Y2s0k/Sm8C5e5eZWbfA34FfKsV29E69W0Km/M6bJUiIl1Z2qDg7m05Wo4DFrn7YgAzu5+g19WGoODuTyelfwU4tQ3ra7lEgkSPzVRtyXgRlohIToiz3mQIsCxpuDIcF+Vs4B8x5qc5M4qL6qiuy6e6ukPXLCLSJcV5ipzqFuGU7RBmdirBndKHREyfAkwBGD58eHvlD4BEscEG2LgRCnSrgojkuDhLCpXAsKThocDHTROZ2deBK4Dx4Y1yzbj7dHcvd/fygQNT9eTdeontgl2gTvFEROINCq8Du5jZSDPrCUwEZiYnMLO9gD8QBIROeWhPok/QbKLLUkVEYgwK7l4DXAA8BrwNPOju883sajMbHyb7NbAd8Gczm5v0DOgOU9wnqEFTUBARibdNAXefBcxqMu7KpM9fj3P92UiU9AIUFEREIN7qo26hPihsWFvbyTkREel8Cgr1z2leub6TcyIi0vlyPigUD0oAUPWpLj8SEcn5oJAYuB0AVauadu0kIpJ7FBS27w3AhlWbOjknIiKdT0FhcB8AqlZv6eSciIh0PgWFISVAxwaFGTNgxAjo0SN4nzGjw1YtIpJWzncP2qO0H4VspGpdx1ySOmMGTJmy9b6IJUv+ZC7hAAAWgUlEQVSCYYDJkzskCyIikXK+pEBBAQk2sqGDgsIVVzS/Ua6qKhgvItLZFBSARN4mqjZkfJBcu1i6NP14VS2JSGdSUACK8zen7OYijgN0VM/f7rDrrnDWWUGVkvvWqiUFBhHpKAoKQKKghqpNjXdFfd1/ex+gf/az5uOKioL2hMWLYUuT9m5VLYlIR1JQABK9atiwqXGbe1x1/4MHB+8DB4IZlJXBbbdBRQXU1aWeJ6rKSUSkveX81UcAicI61q1tvCsy1f231p//DL17w7Jl0KtX42nDhwclkqba+WFzIiKRVFKYMYPiFYupqi5o1HAwJOJp0sOGpR6fjepq+OtfYfz45gEB4NprIZFoPC6RCMaLiHSE3A4KYcNBomYtVSQaGg68YgYDBqSeZf/9W7+6Z5+Fzz+Hk05KPX3yZJg+PahSAujZMxjW/Qsi0lFyOyiEDQcJqthAcTCuqorf/GAxc+fCd74THKDNgiqcceOCM/033mjd6h56CIqL4aijotNMngwffgjTpgWNzuXlrVuXiEhr5HZQCBsIElQFJQXgNfblx19M5YQT4K67ggN0XV1QiPjHP4IG4lNPhY0t7FS1thb+8hc47rjgaqNMJk4MLoXV5agi247ucB9SbgeFsAW3mA1UkWA1fZnI/Qzp8Qm33x6UEJKVlgaB4u234cc/btmqnnsOVq6Mrjpqascd4fDDg6uSvGPuq5NO1h0OGNuSjt7fcV3m3u7cPbYXcDSwEFgETE0x/WDgDaAGOCmbZe6zzz7ebioqvKLgDO/L5w7uRWxwo9pf7nWI+xtvRM520UXu4P7Pf2a/qu9/372oyH39+uznufvuYD0vvpj9PNI9VVS4JxLB913/SiSC8dL+OmN/l5U1Xl/9q6wsvnUmA2Z7NsftbBK15gXkAe8DOwE9gXnA7k3SjABGA/d0RlCoqHBP9Kxu9AUV5NV4RemF7qWl7nPnppyvqsp91Cj3Pn3chw51Nwu+2KgfVE2N++DB7ied1LL8rV0bBJLvfS+7bSkry5wX6Zo6+4CRazpjf5ulXqdZfOtMlm1QiLP6aBywyN0Xu/sW4H5gQpNSyofu/m8g4rateF1xBVRtaXx/QnVtHlcUTguuBT3ooKAep0n5sv4O5LVrobIyc1HwpZfgk0+yrzqq17s3TJgADz7Y/E7nZN2mWJpBLlefpLsvpro6t/dNHOK6DymdqPuNutx9SNlEjta8gJOAPyYNnwbcEpH2LtKUFIApwGxg9vDhw9stcqaN3Ndf3zxBUvmyJWcaF17oXlgYnPm31N/+Fix35szoNJ1x1tPeJZNcrj6prnbv3Tv1dwjBtPz83Nw3cemM/8zPf958fR35PdIFqo9OThEUbo5ImzYoJL/as/oo7Q8jw68m26Jgba37jju6H3986/K4ZYv7gAHup5wSnaaji6VxHMBztfpk9Wr3o44KtjXVgf/SS4MqxFzcN3GqqHDv0aPx/iwqivcAfeaZ7gUFwfGgPthnu772OAnrCkHhAOCxpOHLgcsj0nZKUEh7cMtwpM32IPbii8H4tvzYzj8/KGmsWZN6+pAhHXvQiOMA3tn1rR0l+c+9447BKz/fffr06D9+ruyb1mrNAXPBgmAf9u27df+edVZ8eVy1KvgPT5kSDE+eHLRJZnPhSXudhHWFoJAPLAZGsrWheVRE2k4JCu5pflBRRz5wP/xwr7j6/WaN1FDnV1/dePk//KF7z57BGWFrvfxysPw772w+bf361FmN66ynri56t7TlIBW1u/v3D9a5LUj15wb3n/wk/XzpfopHHul+1VXd5yKD1p7xRs3X2gPmBRcE/8sVK4Lf1557uu+7b+u3K5Prrw/yNm9eMPz888Hw7bdnnre9TsI6PSgEeeBY4F2Cq5CuCMddDYwPP+8LVAIbgFXA/EzLbO+gECnq1zZ5clCfA15hk72MD9yo9SEs9f586gP7bPT33gvmrxte5sNY4scVPd6mf2pdnfvOO7sffnjj8bW17ieeGPxRLrlk658G3I84ok1b7+7N/4g33hgsN+oABe4nnOD+m9+0/I9/zz3Ni/P1w5MmBUG1u19h1do/d6qfYlFRsF+226758jq7vaG9D+Cp5uvVK6iO6dOn5ft0zZpgv5122tZxv/1tMF/EBYdtUlsb/H8POmjruLq64ArGbAJRe5UUu0RQiOPVYUHBPfrXvWZNUO5s8i29w67ev8cq32nQWr+14Ac+mI+Ds11WekXBGY3/HS08uv30p0Hyysqt4y6/PFj1tGmN037/++55ee7/+U/rNzHqrLZXL/czzkj95z755ODsqzUHqWnTgrQDBmzNyz33uF9zTbAtAwYE6+5KB7+WasufO+p7GjasdYEmLlEB7Mc/di8paV1e05WUWlNqveWWIM2rr24dt2pV8Pu68ML22AuNzZoVrO+++xqPv/nmYPzs2ennb6/vWEEhbhH/8FcY5wVsdKOm8QGM9V7R/8LMp0sR//533w2S/rrfNe5mfnf/Hzq4n3NO8+qVzz4L/oCHH56+6iXqDzxtWnBfRaof4pAhabPZqvaN998P1nvccanz+/LLzRthu8LBryVx/bXX4tmGrtbe0N4HcPf02zh8eMv2aV2d+3/9V+oz9EmT3Pv1C+5DSqel3/03vuG+/fbumzc3Hr96dfD/O+ec9PNPmNB8+7plm0Jcry4TFKJ+/aWlPpBPUv9Q+cC9uDj6V5wuYFRU+E4s8gI2u1HrUOe7M9+33DUjyE+TX+pN33nNwf2RR5pPy3RZbVZ/4IhltvQgVVcXBK/evd2XLYve3XGcZbd2vpbE9eHDg4NNfn5wP2R7l3aivsOhQ1u/zLZI9z1FnTDUn2ikcs890b/FqL9MXl70Pn3iiSDN3Xc3n/bkk8G0GTOi89PSKrDFi4Nt/z//J/X0s88ODglRbY4LFgRXLB144DZw9VFcry4TFNL8OoKDdoo/BrXpj7hRp5J9+3pF0dlewKZGo4vY4BX9vu9+663NrlvcUtTHdx/yhe88aK1vKuoXkc+6iKzU+cDeG1P/EfuvS7vtUQepQYOS9lvSr/v2c15ycP/d75pPS/7lZ6yPj5g31V3riZ7VWw/g33vey/KWuVHrZXnLvOJ7z0d+vb16BfXQUXF90CD3225rvj4Izkw//7xj7u+AoA470xlve5s1KzooRB3AITghePbZxsuqrQ2qnMB9t92aX5YbFYTr2xgeeyx1Ho8/PqiK3Lix+bTaWveddnI/7LDobWxpu9D//E8QpKJOeF57LZj/1lubT6urcz/44KDUv2JFdJ6ypaDQEaLOwPuviz6gRv2qUrUYJr3K+CD1Mvkgcp5/9TjKwf2XXNZs2ov5B3uPJlVcW5f5oVf0ONUTrG/8R2S9V/RK07o3aJBXnPhQs/mMWjdq/d7T/9no3/0xg70fn/vBX/7Ea+9JfwpW8b3nmy0Xav3nJ72ZPkhFfBfb963ym057tdkyC6nyS499K7L+O3hFBdPoacP7r0v7m2nLtKaB7eKj5rtZ0MZTe08r19eC/NQNL/Prvz3be/QISkZFBdkH4V9+a7bvumtwPvSdgxb58HBakVU5uJ97bnCvTlTwbpqXjcN39d12XO3DhoWXcCdN+3DIV7yH1frll0dv37XXBnl+7/pHWlcSbpKX/ttt9BNPjN6ndX+q8L33Dq5+qvtT42l3hCdMt92WxXeVBQWFTpT27DRd+TMqYAwf3urSxzd51LdjrS9n+4Zxd3CG92STD+JjL6Sq+YGfSe7gFUxquLqqjA8axmd6NZ3vNs7yQ3jajVo/nTsaphWx3vPY7AvZJXp5PXsG110WFTVa7g585KV86gnW+1+LJ6fM61O9x2c4gLf8ZdT5cFuSOibaisj1GbXBdZBN64+KioKbFO6+O/p38ac/NT9VLioKjhZ//GPK0+hfTZzj4H5F/nWpl5lNHViaqsyKgjMa9ncxQeA9adyHvv6P9zWaVsYHWy+yiFjm6ukP+F5lnzXbZwVs9orzns+Yl6bTXu51iPewWj/3a+82mvZj/q/3oMaX3PiXyGV+dPPD3sNqfWr+r1Oub0hJ0xOT4DW4b1WzZd7Fdxzcn7z88bT7dPrZLzu4v9jrsIbxK+nv/VnpB+66IuMJU7YUFDpZ2sDeisrqVpU+ysr83R0P8R5UezHr3Kj13qxxcP964XO+aujo1Af+srL05eSo1r3tt488ldpIL9+b11P/8TMFm/32Szl+Odv7OF5xqPUCNjeaXF8K6kHzqhxwH8QnaQ/gQ1maevPDfZSyFBXuy6j50m5jO7/qrId/125zCK5+a/T95udHV1Xm53vDqXuq6T17ekXeac22v4DN/qeCM6Lr1oqL006LCrRltiR1nRMEwTBi2qW9bnJwf4KvuYNXUej9Wekn8LD7wIHBK9Uy+/Xzb+bP8sF87FtovA/W9hniZfZhs9+NUesFbPRZfb7VKP2+vOq7Md/rBg4K6tYi1rluwAjvbWv9NO5uGHcGd3g+W/yt0q8G9ZIpd05Zi45JCgrdVWvqxtMEk4rvPe/5bGn8v2eL33PuCy0+A8tqWppgMjyvMvWkvGWZK2sjpm8YsosnbEPKWUvsc7+z30WpD+D9L/SyvGWR+ang2xEH/m+7Dx0aGUwr+l+Yer5+34+ue4jpdTenNqsiTC4JRr4mTkw7PY7A1+p2uIhXFYW+K+/4CBb7Oor9Tk53cH+SwzLO+yjfdHB/hPEN47aQ70fxD8+j2i/jukbf/a2c53sxx/Oo9nP4fcM0cP8Od2aV3+9zi/dio6+ixJ/mEAf3qfwi/XwtvMRMQWEb1JrSR2sbaFs9LW0DfNSZeV2bqjMyLTeqOiNVO0WC9UF9dVlZdCmqBVUrjapP0n0ZMUxLF/RaG4S9rMzTVpF1dF6jpg0b5i8MmOBQ69uxxqHO8+tLpYMHu++wQ+R81cNG+g585Mcx0x28Dvx07nRwv73kkpTzrd3+S75H3vxmk4rY4BV9znN/5ZXo67wHD/Z5/Q9zcO/H5w51nscWv4PTg9L39ttHb38LKCiIu3fSdexxBKiYlhvZgNmS607bIWDGMa29g3B1UW+/5NjmB76G/Z3hyrRMJdrIAN2GZTYtJWe7zPE206HOjVrvyxcO7ledOC/tfMP7p25vKEu+yCBNXlOW6jLltQUUFMTdW34JXZza6bfdYcttjys+WrTMdp4W9d3vsEOW25c0fdXQ0X7EHsEd+kcckf4y39ZuR7ZXGLV1+zOdLFRUuBc2uYIqr0dtxu3L6gQsrhOmLCgoiLvHeMBsQ37a+zgb53K7s1TfvVnQ3ptNHz/J+zQ/P7jevr4Dt+6wv1tbSm7tiVRbTsA6okSvoCANusMfWOLR9Lu/4YagL53SUvc330w/X6qb97rTb6e1B+nWHqDbcgLWESV6BQURSen994PAUFwcVCUlnyzU1QWliBT9PXZatWNrtfYg3ZYDdGtPwDqiRK+gICKRbrih+Rlxfn70JfFxVGd0hNYcpDuryjXuEn22QcGCtN1HeXm5z549u7OzIdKtjRgBS5Y0H19YCDfdBFdfDZWVzaeXlcGHH8adu843YwZccQUsXQrDh8O118LkyZ2dq7YxsznuXp4pXX5HZEZEupalS1OP37wZzjkHEgmYMgWqqrZOSySCg2MumDy5+weB1urR2RkQkY43fHj68ZMnw/TpQcnALHifPj13D5S5REFBJAdde21w5p+saUlg8uSgqqiuLnhXQMgNCgoiOUglAYkSa1Aws6PNbKGZLTKzqSmm9zKzB8Lpr5rZiDjzIyJbqSQgqcQWFMwsD7gVOAbYHZhkZrs3SXY28IW7fwn4DfDLuPIjIiKZxVlSGAcscvfF7r4FuB+Y0CTNBODu8PNDwOFmZjHmSURE0ogzKAwBliUNV4bjUqZx9xpgDdC/6YLMbIqZzTaz2StXrowpuyIiEmdQSHXG3/ROuWzS4O7T3b3c3csHDhzYLpkTEZHm4gwKlcCwpOGhwMdRacwsH+gLfB5jnkREJI0472h+HdjFzEYCHwETgW83STMTOB14GTgJeMoz9LsxZ86cz8wsxQ36WRkAfNbKebd12jfRtG+iad+k1hX3S1k2iWILCu5eY2YXAI8BecAd7j7fzK4m6JhpJnA78CczW0RQQpiYxXJbXX9kZrOz6fsjF2nfRNO+iaZ9k1p33i+x9n3k7rOAWU3GXZn0eRNwcpx5EBGR7OmOZhERaZBrQWF6Z2egC9O+iaZ9E037JrVuu1+63fMUREQkPrlWUhARkTQUFEREpEHOBIVMPbbmEjO7w8w+NbO3ksaVmtnjZvZe+F7SmXnsDGY2zMyeNrO3zWy+mV0Ujte+MSs0s9fMbF64b34Wjh8Z9nD8Xtjjcc/OzmtnMbM8M3vTzP4WDnfLfZMTQSHLHltzyV3A0U3GTQWedPddgCfD4VxTA1zi7rsB+wPnh78T7RvYDHzN3ccAY4GjzWx/gp6NfxPumy8Iej7OVRcBbycNd8t9kxNBgex6bM0Z7v4czbsTSe6x9m7g+A7NVBfg7svd/Y3w8zqCP/gQtG/wwPpwsCB8OfA1gh6OIUf3DYCZDQW+AfwxHDa66b7JlaCQTY+tuW57d18OwcERGNTJ+elU4QOf9gJeRfsGaKgemQt8CjwOvA+sDns4htz+X90I/A9QFw73p5vum1wJCln1xioCYGbbAQ8DF7v72s7OT1fh7rXuPpagc8txwG6pknVsrjqfmR0HfOruc5JHp0jaLfZNrN1cdCHZ9Nia61aY2Q7uvtzMdiA4G8w5ZlZAEBBmuPtfwtHaN0ncfbWZPUPQ7tLPzPLDM+Jc/V8dCIw3s2OBQqAPQcmhW+6bXCkpNPTYGl4BMJGgh1bZqr7HWsL3RzsxL50irAe+HXjb3W9ImqR9YzbQzPqFn4uArxO0uTxN0MMx5Oi+cffL3X2ou48gOLY85e6T6ab7JmfuaA6j+I1s7bH12k7OUqcxs/uAQwm6910B/BR4BHgQGA4sBU5295x6toWZHQQ8D/yHrXXDPyFoV8j1fTOaoLE0j+Bk8kF3v9rMdiK4cKMUeBM41d03d15OO5eZHQpc6u7Hddd9kzNBQUREMsuV6iMREcmCgoKIiDRQUBARkQYKCiIi0kBBQUREGigoSM4ys/5mNjd8fWJmHyUNZ9WjpZndaWZfzpDmfDOb3D65FomXLkkVAczsKmC9u1/fZLwR/E/qUs4oso1RSUGkCTP7kpm9ZWa/B94AdjCz6WY2O3yWwJVJaV8ws7Fmlm9mq83suvCZAy+b2aAwzTVmdnFS+uvCZxMsNLOvhOOLzezhcN77wnWN7Yztl9ymoCCS2u7A7e6+l7t/BEx193JgDHBExPM4+gLPhs8ceBk4K2LZ5u7jgMuA+gBzIfBJOO91BD20inQ4BQWR1N5399eThieZ2RsEJYfdCIJGUxvd/R/h5znAiIhl/yVFmoMIukTA3ecB81udc5E2yJVeUkVaakP9BzPbheCpWuPCHkIrCHrDbGpL0udaov9fm1OkSdXVskiHU0lBJLM+wDpgbdh19lExrOMF4BQAM9uT1CURkdippCCS2RvAAuAtYDHwYgzruBm4x8z+Ha7vLWBNDOsRSUuXpIp0AWaWD+S7+6awuupfwC5Jj3MU6RAqKYh0DdsBT4bBwYBzFRCkM6ikICIiDdTQLCIiDRQURESkgYKCiIg0UFAQEZEGCgoiItLg/wMIE6gGOZT6GwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = 'Learning Curve'\n",
    "plt.title(title)\n",
    "plt.plot([i[1] for i in loss_hist], 'o-', color=\"r\",label= \"Training batch\")\n",
    "plt.plot([i[0] for i in loss_hist],  'o-', color=\"b\", label=\"CV set\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"Training\")\n",
    "plt.ylabel(\"BCEWithLogitsLoss\")\n",
    "plt.savefig('../plots_tables/'+title.replace(' ', '_')+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(pred, labels, thre= 0.5):\n",
    "    toxic_labels = ['toxic','severe_toxic',\n",
    "               'obscene','threat','insult',\n",
    "               'identity_hate']\n",
    "    \n",
    "    roc_auc_scores= []\n",
    "    recall_scores=[]\n",
    "    precision_scores=[]\n",
    "    accuracy_scores=[]\n",
    "    f1_scores=[]\n",
    "\n",
    "     \n",
    "    for i,j in enumerate(toxic_labels):\n",
    "        roc_auc_scores.append(roc_auc_score(labels[:,i], pred[:,i]))\n",
    "        recall_scores.append(recall_score(labels[:,i], pred[:,i]>=thre))\n",
    "        accuracy_scores.append(accuracy_score(labels[:,i], pred[:,i]>=thre))\n",
    "        precision_scores.append(precision_score(labels[:,i], pred[:,i]>=thre))\n",
    "        f1_scores.append(f1_score(labels[:,i], pred[:,i]>=thre))\n",
    "    return pd.DataFrame(\n",
    "    {'Label': toxic_labels,\n",
    "     'accuracy': accuracy_scores,\n",
    "     'recall': recall_scores,\n",
    "     'precision': precision_scores,\n",
    "     'f1': f1_scores,\n",
    "     'roc_auc': roc_auc_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.954753</td>\n",
       "      <td>0.609227</td>\n",
       "      <td>0.860153</td>\n",
       "      <td>0.713264</td>\n",
       "      <td>0.954455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.990913</td>\n",
       "      <td>0.163399</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.986255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.976374</td>\n",
       "      <td>0.653236</td>\n",
       "      <td>0.851911</td>\n",
       "      <td>0.739461</td>\n",
       "      <td>0.979860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.997681</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.926899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.971611</td>\n",
       "      <td>0.552457</td>\n",
       "      <td>0.781955</td>\n",
       "      <td>0.647471</td>\n",
       "      <td>0.968506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.992918</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.162963</td>\n",
       "      <td>0.952552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Label  accuracy    recall  precision        f1   roc_auc\n",
       "0          toxic  0.954753  0.609227   0.860153  0.713264  0.954455\n",
       "1   severe_toxic  0.990913  0.163399   0.595238  0.256410  0.986255\n",
       "2        obscene  0.976374  0.653236   0.851911  0.739461  0.979860\n",
       "3         threat  0.997681  0.051282   1.000000  0.097561  0.926899\n",
       "4         insult  0.971611  0.552457   0.781955  0.647471  0.968506\n",
       "5  identity_hate  0.992918  0.090909   0.785714  0.162963  0.952552"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_metrics(_preds , _labels,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "_predicted_labels = _preds  \n",
    "_true_labels = _labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rene/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/rene/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "roc_auc_scores= []\n",
    "recall_scores=[]\n",
    "precision_scores=[]\n",
    "accuracy_scores=[]\n",
    "f1_scores=[]\n",
    "\n",
    "thre = 0.5\n",
    "for i,j in enumerate(toxic_labels):\n",
    "    roc_auc_scores.append(roc_auc_score(_true_labels[:,i], _predicted_labels[:,i]))\n",
    "    recall_scores.append(recall_score(_true_labels[:,i], _predicted_labels[:,i]>=thre))\n",
    "    accuracy_scores.append(accuracy_score(_true_labels[:,i], _predicted_labels[:,i]>=thre))\n",
    "    precision_scores.append(precision_score(_true_labels[:,i], _predicted_labels[:,i]>=thre))\n",
    "    f1_scores.append(f1_score(_true_labels[:,i], _predicted_labels[:,i]>=thre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.959955</td>\n",
       "      <td>0.685306</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.767383</td>\n",
       "      <td>0.974273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.990224</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>0.982650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.979821</td>\n",
       "      <td>0.776978</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>0.800989</td>\n",
       "      <td>0.990320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.996365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.971068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.972614</td>\n",
       "      <td>0.552564</td>\n",
       "      <td>0.830443</td>\n",
       "      <td>0.663587</td>\n",
       "      <td>0.982024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.992605</td>\n",
       "      <td>0.179104</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.289157</td>\n",
       "      <td>0.974340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Label  accuracy    recall  precision        f1   roc_auc\n",
       "0          toxic  0.959955  0.685306   0.871795  0.767383  0.974273\n",
       "1   severe_toxic  0.990224  0.164706   0.666667  0.264151  0.982650\n",
       "2        obscene  0.979821  0.776978   0.826531  0.800989  0.990320\n",
       "3         threat  0.996365  0.000000   0.000000  0.000000  0.971068\n",
       "4         insult  0.972614  0.552564   0.830443  0.663587  0.982024\n",
       "5  identity_hate  0.992605  0.179104   0.750000  0.289157  0.974340"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "{'Label': toxic_labels,\n",
    " 'accuracy': accuracy_scores,\n",
    " 'recall': recall_scores,\n",
    " 'precision': precision_scores,\n",
    " 'f1': f1_scores,\n",
    " 'roc_auc': roc_auc_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.960926</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.875796</td>\n",
       "      <td>0.779175</td>\n",
       "      <td>0.969787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.989284</td>\n",
       "      <td>0.364162</td>\n",
       "      <td>0.508065</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.986377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.980228</td>\n",
       "      <td>0.754051</td>\n",
       "      <td>0.863486</td>\n",
       "      <td>0.805066</td>\n",
       "      <td>0.990308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.996428</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.970779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.973241</td>\n",
       "      <td>0.625778</td>\n",
       "      <td>0.798887</td>\n",
       "      <td>0.701816</td>\n",
       "      <td>0.982739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.992699</td>\n",
       "      <td>0.407143</td>\n",
       "      <td>0.629834</td>\n",
       "      <td>0.494577</td>\n",
       "      <td>0.978494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Label  accuracy    recall  precision        f1   roc_auc\n",
       "0          toxic  0.960926  0.701754   0.875796  0.779175  0.969787\n",
       "1   severe_toxic  0.989284  0.364162   0.508065  0.424242  0.986377\n",
       "2        obscene  0.980228  0.754051   0.863486  0.805066  0.990308\n",
       "3         threat  0.996428  0.058333   0.875000  0.109375  0.970779\n",
       "4         insult  0.973241  0.625778   0.798887  0.701816  0.982739\n",
       "5  identity_hate  0.992699  0.407143   0.629834  0.494577  0.978494"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "{'Label': toxic_labels,\n",
    " 'accuracy': accuracy_scores,\n",
    " 'recall': recall_scores,\n",
    " 'precision': precision_scores,\n",
    " 'f1': f1_scores,\n",
    " 'roc_auc': roc_auc_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.960268</td>\n",
       "      <td>0.696332</td>\n",
       "      <td>0.873549</td>\n",
       "      <td>0.774938</td>\n",
       "      <td>0.969681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.989597</td>\n",
       "      <td>0.355491</td>\n",
       "      <td>0.530172</td>\n",
       "      <td>0.425606</td>\n",
       "      <td>0.986533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.980698</td>\n",
       "      <td>0.769097</td>\n",
       "      <td>0.859638</td>\n",
       "      <td>0.811851</td>\n",
       "      <td>0.990549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.996397</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.094488</td>\n",
       "      <td>0.970718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.972332</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>0.777863</td>\n",
       "      <td>0.696250</td>\n",
       "      <td>0.982357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.992448</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.445977</td>\n",
       "      <td>0.978640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Label  accuracy    recall  precision        f1   roc_auc\n",
       "0          toxic  0.960268  0.696332   0.873549  0.774938  0.969681\n",
       "1   severe_toxic  0.989597  0.355491   0.530172  0.425606  0.986533\n",
       "2        obscene  0.980698  0.769097   0.859638  0.811851  0.990549\n",
       "3         threat  0.996397  0.050000   0.857143  0.094488  0.970718\n",
       "4         insult  0.972332  0.630137   0.777863  0.696250  0.982357\n",
       "5  identity_hate  0.992448  0.346429   0.625806  0.445977  0.978640"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "{'Label': toxic_labels,\n",
    " 'accuracy': accuracy_scores,\n",
    " 'recall': recall_scores,\n",
    " 'precision': precision_scores,\n",
    " 'f1': f1_scores,\n",
    " 'roc_auc': roc_auc_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.vocab.vectors = model.embedding.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './custom_embeddings/train_data_field'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-311-f91d2324caac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./custom_embeddings/train_data_field'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './custom_embeddings/train_data_field'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(TEXT, open('./custom_embeddings/train_data_field', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "word_list = [] \n",
    "def write_embeddings(path, embeddings, vocab):\n",
    "    \n",
    "    with open(path, 'w') as f:\n",
    "        for i, embedding in enumerate(tqdm(embeddings)):\n",
    "            word = vocab.itos[i]\n",
    "            #skip words with unicode symbols\n",
    "            if len(word) != len(word.encode()):\n",
    "                continue\n",
    "            word_list.append(word)\n",
    "            vector = ' '.join([str(i) for i in embedding.tolist()])\n",
    "            f.write(f'{word} {vector}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20002/20002 [00:02<00:00, 8001.79it/s]\n"
     ]
    }
   ],
   "source": [
    "write_embeddings('embeddings_conv.txt', \n",
    "                 model.embedding.weight.data, \n",
    "                 TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19951"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_apos = [w for w in word_list if ('\\'' in w) | ('<' in w) | ('>' in w) ]\n",
    "len(word_list) - len(list_apos)\n",
    "#list_apos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
      "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
      "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
      "        ...,\n",
      "        [-1.0361, -0.3528, -0.4494,  ..., -0.3391, -0.0521, -0.2626],\n",
      "        [-0.8892,  0.3043,  0.9224,  ..., -0.2417, -0.1520,  0.0683],\n",
      "        [ 0.2916,  0.0795, -0.0095,  ...,  0.3854,  0.3772, -1.5852]])\n"
     ]
    }
   ],
   "source": [
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FREEZE_FOR = 4\n",
    "\n",
    "\n",
    "#best_valid_loss = float('inf')\n",
    "\n",
    "#freeze embeddings\n",
    "#model.embedding.weight.requires_grad = unfrozen = False\n",
    "\n",
    "#for epoch in range(N_EPOCHS):\n",
    "\n",
    "#    start_time = time.time()\n",
    "    \n",
    "#    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "#    print('jaja')\n",
    "#    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "#    print('juju')\n",
    "#    end_time = time.time()\n",
    "\n",
    "#    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "#    if valid_loss < best_valid_loss:\n",
    "#        best_valid_loss = valid_loss\n",
    "#        torch.save(model.state_dict(), 'tut2-model.pt')\n",
    "#    else:\n",
    "#        #unfreeze embeddings\n",
    "#        model.embedding.weight.requires_grad = unfrozen = True\n",
    "\n",
    "    \n",
    "#    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "#    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "#    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#roc_auc(np.vstack(preds_list), np.vstack(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFields = {\"comment_text\": (\"comment_text\", TEXT)}\n",
    "\n",
    "testDataset= data.TabularDataset(path='./data/test.json', \n",
    "                                            format='json',\n",
    "                                            fields=dataFields, \n",
    "                                            skip_header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153164"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterator = torchtext.data.Iterator(testDataset, batch_size=64, device=device, \n",
    "                                     sort=False, sort_within_batch=False, \n",
    "                                     repeat=False,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPreds=[]\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for batch in test_iterator:\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "        text = batch.comment_text    \n",
    "        predictions = model(text).squeeze(1)         \n",
    "        myPreds+=[torch.sigmoid(predictions).detach().numpy()]\n",
    "    \n",
    "        torch.cuda.empty_cache()\n",
    "myPreds = np.vstack(myPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF= pd.read_csv(\"./data/test.csv\")\n",
    "for i, col in enumerate([\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]):\n",
    "    testDF[col] = myPreds[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 6)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myPreds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF.drop(\"comment_text\", axis=1).to_csv(\"submission_convolutional.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
